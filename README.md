# Architecture Technique - Projet Score Credit ML

## üìã Table des Mati√®res
1. [Vue d'ensemble](#vue-densemble)
2. [Architecture Global](#architecture-global)
3. [Composantes Principales](#composantes-principales)
4. [Stack Technologique](#stack-technologique)
5. [Flux de Donn√©es](#flux-de-donn√©es)
6. [Infrastructure & D√©ploiement](#infrastructure--d√©ploiement)
7. [Mod√®le ML D√©tails](#mod√®le-ml-d√©tails)
8. [API REST Endpoints](#api-rest-endpoints)
9. [Monitoring & Observabilit√©](#monitoring--observabilit√©)

---

## Vue d'ensemble

Le projet **score-credit-project** est une application **Production-Ready** de pr√©diction de score de cr√©dit bas√©e sur le Machine Learning. L'architecture suit un pattern moderne avec :

- **Frontend** : Interface web vanilla (HTML/CSS/JavaScript)
- **Backend** : API REST asynchrone (FastAPI)
- **ML Model** : RandomForest avec preprocessing complexe (scikit-learn)
- **Model Registry** : MLflow pour versioning et gestion des mod√®les
- **Monitoring** : Stack complet Prometheus + Grafana
- **Conteneurisation** : Docker & Docker Compose

---

## Architecture Global

### Sch√©ma Haut Niveau

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     Client Web                               ‚îÇ
‚îÇ              (HTML/CSS/JavaScript - Port 8000)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ HTTP REST
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  FastAPI Backend                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Endpoints: /api/predict, /api/predict-batch       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Validation: Pydantic Models                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ ML Pipeline: Preprocessing + RandomForest         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Caching: ModelCache Singleton                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Metrics: Prometheus Integration                   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                          ‚îÇ
             ‚ñº                          ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ MLflow Registry ‚îÇ        ‚îÇ Prometheus Metrics‚îÇ
    ‚îÇ (Model Store)   ‚îÇ        ‚îÇ (Time-Series DB) ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                          ‚îÇ
             ‚ñº                          ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         Grafana Dashboards               ‚îÇ
    ‚îÇ    (Real-time ML & API Monitoring)       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Composantes Principales

### 1Ô∏è‚É£ Frontend (Client-Side)

**Localisation**: `templates/index.html`

**Caract√©ristiques**:
- Vanilla JavaScript (pas de framework)
- Design moderne avec palette Midnight Vault
- Responsive layout (Space Grotesk font)
- Form handling avec validation c√¥t√© client
- AJAX requests asynchrones
- Affichage du r√©sultat de pr√©diction avec indicateurs visuels

**Technologies**:
- HTML5
- CSS3 (Flexbox, Grid, Animations)
- JavaScript ES6+
- Fetch API pour les requ√™tes HTTP

---

### 2Ô∏è‚É£ Backend API (FastAPI)

**Localisation**: `main.py`

**Architecture**:

```
FastAPI Application
‚îú‚îÄ‚îÄ Routes
‚îÇ   ‚îú‚îÄ‚îÄ GET /                    ‚Üí Home page
‚îÇ   ‚îú‚îÄ‚îÄ GET /api/health          ‚Üí Health check
‚îÇ   ‚îú‚îÄ‚îÄ GET /api/model-info      ‚Üí Model metadata
‚îÇ   ‚îú‚îÄ‚îÄ POST /api/predict        ‚Üí Single prediction
‚îÇ   ‚îú‚îÄ‚îÄ POST /api/predict-batch  ‚Üí Batch predictions
‚îÇ   ‚îú‚îÄ‚îÄ POST /api/reload-model   ‚Üí Reload model
‚îÇ   ‚îú‚îÄ‚îÄ GET /metrics             ‚Üí Prometheus metrics
‚îÇ   ‚îî‚îÄ‚îÄ GET /docs                ‚Üí Swagger UI
‚îÇ
‚îú‚îÄ‚îÄ Data Models (Pydantic)
‚îÇ   ‚îú‚îÄ‚îÄ CreditApplicationInput   ‚Üí Input schema
‚îÇ   ‚îú‚îÄ‚îÄ PredictionResponse       ‚Üí Output schema
‚îÇ   ‚îú‚îÄ‚îÄ BatchPredictionRequest   ‚Üí Batch input
‚îÇ   ‚îî‚îÄ‚îÄ BatchPredictionResponse  ‚Üí Batch output
‚îÇ
‚îú‚îÄ‚îÄ ML Processing
‚îÇ   ‚îú‚îÄ‚îÄ ModelCache               ‚Üí Model loading & caching
‚îÇ   ‚îú‚îÄ‚îÄ Preprocessor             ‚Üí Data transformation
‚îÇ   ‚îî‚îÄ‚îÄ RandomForest             ‚Üí Predictions
‚îÇ
‚îú‚îÄ‚îÄ Monitoring
‚îÇ   ‚îú‚îÄ‚îÄ Prometheus Metrics       ‚Üí Counter, Histogram, Gauge
‚îÇ   ‚îú‚îÄ‚îÄ prometheus-fastapi-instrumentator
‚îÇ   ‚îî‚îÄ‚îÄ Health checks
‚îÇ
‚îî‚îÄ‚îÄ Error Handling
    ‚îî‚îÄ‚îÄ Global exception handler
```

**D√©tails du Flow Request**:

1. **Input Validation** : Pydantic valide JSON contre `CreditApplicationInput`
2. **Data Preprocessing** : `CustomPreprocessor` transforme les donn√©es
3. **Model Loading** : `ModelCache` charge depuis MLflow Registry
4. **Prediction** : `model.predict()` + `model.predict_proba()`
5. **Risk Calculation** : Niveau de risque bas√© sur probability
6. **Metrics Recording** : Prometheus metrics incr√©ment√©es
7. **Response** : JSON s√©rialis√© avec timestamp

---

### 3Ô∏è‚É£ Machine Learning Pipeline

**Composantes**:

#### 3.1 Features d'Entr√©e (21 total)

**Num√©riques (6)**:
```
- Duration in month (1-120)
- Credit amount (>0)
- Installment rate (1-4%)
- Age in years (18-100)
- Number of existing credits (1-4)
- Number of dependents (1-2)
```

**Ordinales (5)** - Codes A** avec mappings:
```
- Status of checking account (A11‚Üí0, A12‚Üí1, A13‚Üí2, A14‚Üí3)
- Credit history (A30‚Üí0 ... A34‚Üí4)
- Savings account (A61‚Üí0 ... A65‚Üí4)
- Employment since (A71‚Üí0 ... A75‚Üí4)
- Job (A171‚Üí0, A172‚Üí1, A173‚Üí2, A174‚Üí3)
```

**Nominales (8)** - Cat√©gories sans ordre:
```
- Purpose (A43, A44, ...)
- Personal status & sex (A93, A94, ...)
- Other debtors (A101, A102, ...)
- Property (A121, A122, ...)
- Other installment plans (A143, A144, ...)
- Housing (A151, A152, A153)
- Telephone (A191, A192)
- Foreign worker (A201, A202)
```

#### 3.2 Preprocessing Pipeline

```python
Pipeline([
    ('preprocessor', CustomPreprocessor([
        1. Apply ordinal mappings (A11‚Üí0, etc)
        2. One-Hot Encoding for nominal features
        3. StandardScaler on numerical features
    ])),
    ('classifier', RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        min_samples_split=20,
        min_samples_leaf=10,
        random_state=42
    ))
])
```

#### 3.3 Mod√®le RandomForest

**Configuration**:
```
n_estimators: 100 trees
max_depth: 10 levels
min_samples_split: 20 samples
min_samples_leaf: 10 samples
random_state: 42 (reproducibilit√©)
n_jobs: -1 (parall√©lisation)
```

**Output**:
- `predict()` : 0 (Bad Credit) ou 1 (Good Credit)
- `predict_proba()` : [P_bad, P_good] ‚àà [0,1]

#### 3.4 Risk Level Classification

```
IF P_good >= 0.7    ‚Üí RISK = LOW
ELIF P_good >= 0.4  ‚Üí RISK = MEDIUM
ELSE (P_good < 0.4) ‚Üí RISK = HIGH
```

---

### 4Ô∏è‚É£ MLflow Model Registry

**Purpose**: Version control, artifact storage, model promotion

**Structure**:

```
MLflow Setup
‚îú‚îÄ‚îÄ Tracking URI: sqlite:///mlflow.db
‚îú‚îÄ‚îÄ Experiment: credit-score-production
‚îú‚îÄ‚îÄ Runs: Each training session
‚îÇ   ‚îî‚îÄ‚îÄ Artifacts:
‚îÇ       ‚îú‚îÄ‚îÄ classification_report.txt
‚îÇ       ‚îú‚îÄ‚îÄ confusion_matrix.txt
‚îÇ       ‚îú‚îÄ‚îÄ model_metadata.json
‚îÇ       ‚îú‚îÄ‚îÄ conda.yaml
‚îÇ       ‚îú‚îÄ‚îÄ python_env.yaml
‚îÇ       ‚îú‚îÄ‚îÄ MLmodel (config)
‚îÇ       ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ       ‚îî‚îÄ‚îÄ model.pkl
‚îÇ
‚îî‚îÄ‚îÄ Model Registry
    ‚îî‚îÄ‚îÄ RDF_score_pipeline
        ‚îú‚îÄ‚îÄ Version 1: Staging
        ‚îú‚îÄ‚îÄ Version 2: Production ‚Üê Used by API
        ‚îî‚îÄ‚îÄ Version 3: None
```

**Workflow**:
1. Script ex√©cute l'entra√Ænement
2. MLflow logs les m√©triques, params, artifacts
3. Mod√®le enregistr√© dans Model Registry
4. Promotion manuelle vers "Production" stage
5. API charge depuis `models:/RDF_score_pipeline/Production`

---

### 5Ô∏è‚É£ MLflow Database

**Type**: SQLite (fichier local `mlflow.db`)

**Contenu**:
- Experiment metadata
- Run information (run_id, timestamps, parameters)
- Metric history (accuracy, loss, etc.)
- Model registry entries
- Artifact location references

---

## Stack Technologique

### Backend Stack

| Composant | Technologie | Version | Usage |
|-----------|------------|---------|-------|
| **Runtime** | Python | 3.13.2 | Language |
| **Web Framework** | FastAPI | Latest | REST API |
| **Web Server** | Uvicorn | With standard extras | ASGI Server |
| **ML Framework** | scikit-learn | 1.8.0 | Model training & inference |
| **Data Processing** | pandas | 2.3.3 | DataFrame operations |
| **Numerical** | numpy | (via pandas) | Array operations |
| **Serialization** | joblib | 1.5.2 | Model saving |
| **Model Registry** | MLflow | Latest | Version control |
| **Validation** | Pydantic | (FastAPI included) | Input validation |
| **Monitoring** | prometheus-client | ‚â•0.17.0 | Metrics export |
| **FastAPI Integration** | prometheus-fastapi-instrumentator | ‚â•6.0.0 | Auto-instrumentation |
| **CORS** | FastAPI middleware | Built-in | Cross-origin requests |

### Infrastructure Stack

| Composant | Technologie | Purpose |
|-----------|------------|---------|
| **Conteneurisation** | Docker | Container images |
| **Orchestration** | Docker Compose | Multi-container setup |
| **Monitoring (Metrics)** | Prometheus | Time-series database |
| **Monitoring (Visualization)** | Grafana | Dashboards & alerts |
| **Base Image** | python:3.13.2-slim | Lightweight Python runtime |

### Frontend Stack

| Composant | Technologie | Purpose |
|-----------|------------|---------|
| **Structure** | HTML5 | Markup |
| **Styling** | CSS3 | Layout & design |
| **Interactivit√©** | Vanilla JavaScript | Logic & API calls |
| **Font** | Space Grotesk (Google Fonts) | Typography |
| **API Client** | Fetch API | HTTP requests |

---

## Flux de Donn√©es

### üîÑ Flux Training (Offline - script.py)

```
1. Load Data
   ‚îî‚îÄ CSV (estadistical.csv) ‚Üí Pandas DataFrame
   
2. Data Cleaning
   ‚îî‚îÄ Column normalization, target mapping (2‚Üí0, 1‚Üí1)
   
3. Train/Test Split
   ‚îî‚îÄ 70% train, 30% test (stratified)
   
4. Feature Separation
   ‚îú‚îÄ Numerical features (6)
   ‚îú‚îÄ Ordinal categorical (5)
   ‚îî‚îÄ Nominal categorical (8)
   
5. Preprocessing Fit
   ‚îî‚îÄ CustomPreprocessor.fit(X_train)
      ‚îú‚îÄ Learn ordinal mappings
      ‚îú‚îÄ Learn one-hot categories
      ‚îî‚îÄ Fit StandardScaler
   
6. Model Training
   ‚îî‚îÄ Pipeline.fit(X_train, y_train)
      ‚îî‚îÄ RandomForestClassifier(100 trees)
   
7. Evaluation
   ‚îú‚îÄ predict(X_test) ‚Üí y_pred
   ‚îú‚îÄ predict_proba(X_test) ‚Üí probabilities
   ‚îú‚îÄ Accuracy calculation
   ‚îú‚îÄ Classification report
   ‚îî‚îÄ Confusion matrix
   
8. MLflow Logging
   ‚îú‚îÄ Log metrics (accuracy)
   ‚îú‚îÄ Log parameters (n_estimators, etc.)
   ‚îú‚îÄ Log artifacts (reports)
   ‚îú‚îÄ Log model (entire pipeline)
   ‚îî‚îÄ Create model signature
   
9. Model Registration
   ‚îî‚îÄ MLflow Model Registry
      ‚îî‚îÄ RDF_score_pipeline (new version)
   
10. Promotion
    ‚îî‚îÄ Stage: Staging ‚Üí Production
       ‚îî‚îÄ Archive previous Production version
```

### üéØ Flux Inference (Online - API)

```
1. Client Request
   ‚îî‚îÄ HTTP POST /api/predict
      ‚îî‚îÄ JSON payload with 21 features
   
2. Input Validation
   ‚îî‚îÄ Pydantic validates against CreditApplicationInput
      ‚îî‚îÄ Type checking, range validation, field aliases
   
3. Convert to DataFrame
   ‚îî‚îÄ CreditApplicationInput.to_dataframe()
      ‚îî‚îÄ Original column names restored
   
4. Load Model (from Cache)
   ‚îî‚îÄ ModelCache.get_model()
      ‚îú‚îÄ Check if in memory cache
      ‚îî‚îÄ If not, load from MLflow Registry
   
5. Preprocessing
   ‚îî‚îÄ CustomPreprocessor.transform(X)
      ‚îú‚îÄ Ordinal mapping (A12‚Üí1, etc.)
      ‚îú‚îÄ One-Hot Encoding
      ‚îî‚îÄ StandardScaler (using training statistics)
   
6. Model Prediction
   ‚îú‚îÄ prediction = model.predict(X)[0] ‚Üí 0 or 1
   ‚îî‚îÄ probabilities = model.predict_proba(X)[0] ‚Üí [P_bad, P_good]
   
7. Risk Calculation
   ‚îî‚îÄ risk_level = calculate_risk_level(P_good)
      ‚îî‚îÄ LOW / MEDIUM / HIGH
   
8. Metrics Recording
   ‚îú‚îÄ prediction_counter.inc() ‚Üí total count
   ‚îú‚îÄ prediction_good_credit.inc() (if pred==1)
   ‚îú‚îÄ prediction_latency.observe(duration) ‚Üí histogram
   ‚îî‚îÄ Send to Prometheus
   
9. Response Building
   ‚îî‚îÄ PredictionResponse {
      ‚îú‚îÄ prediction (int): 0 or 1
      ‚îú‚îÄ probability_good_credit (float)
      ‚îú‚îÄ probability_bad_credit (float)
      ‚îú‚îÄ risk_level (str): LOW/MEDIUM/HIGH
      ‚îú‚îÄ model_version (str)
      ‚îî‚îÄ timestamp (str)
   }
   
10. Return to Client
    ‚îî‚îÄ HTTP 200 OK
       ‚îî‚îÄ JSON response
```

---

## Infrastructure & D√©ploiement

### Docker Configuration

**Base Image**: `python:3.13.2-slim`

**Layers**:
1. Update apt, install gcc/g++ (compilation tools)
2. Copy requirements.txt
3. Pip install Python dependencies
4. Copy project files
5. Create /app/model directory
6. Copy model.pkl from mlruns

**Healthcheck**: 
```bash
python -c "import requests; requests.get('http://localhost:8000/api/health')"
Interval: 30s | Timeout: 10s | Retries: 3 | Start period: 10s
```

**Volume Mounts**:
```yaml
volumes:
  - ./mlruns:/app/mlruns           # Model artifacts sync
  - ./mlflow.db:/app/mlflow.db     # MLflow database sync
```

**Environment Variables**:
```
MLFLOW_TRACKING_URI=sqlite:///mlflow.db
```

### Docker Compose Services

#### Service 1: API (credit-score-api)

```yaml
build: .                           # Build from Dockerfile
container_name: credit-score-api
ports:
  - "8000:8000"                    # API endpoint
environment:
  - MLFLOW_TRACKING_URI=sqlite:///mlflow.db
volumes:
  - ./mlruns:/app/mlruns
  - ./mlflow.db:/app/mlflow.db
networks:
  - monitoring
healthcheck: ‚úì enabled
depends_on:
  - prometheus
```

#### Service 2: Prometheus

```yaml
image: prom/prometheus:latest
container_name: prometheus
ports:
  - "9090:9090"                    # Metrics UI
volumes:
  - ./prometheus.yml:/etc/prometheus/prometheus.yml
  - prometheus-data:/prometheus    # Named volume
command:
  - '--config.file=/etc/prometheus/prometheus.yml'
  - '--storage.tsdb.path=/prometheus'
  - '--storage.tsdb.retention.time=30d'
networks:
  - monitoring
healthcheck: ‚úì enabled
```

#### Service 3: Grafana

```yaml
image: grafana/grafana:latest
container_name: grafana
ports:
  - "3000:3000"                    # Dashboard UI
environment:
  - GF_SECURITY_ADMIN_USER=admin
  - GF_SECURITY_ADMIN_PASSWORD=admin123
  - GF_INSTALL_PLUGINS=
  - GF_USERS_ALLOW_SIGN_UP=false
volumes:
  - grafana-data:/var/lib/grafana
  - ./grafana/provisioning:/etc/grafana/provisioning
networks:
  - monitoring
depends_on:
  - prometheus
healthcheck: ‚úì enabled
```

### Network & Volumes

**Network**: `monitoring` (bridge driver)
- Enables inter-container communication
- Services accessible by name (credit-score-api, prometheus, grafana)

**Named Volumes**:
- `prometheus-data`: Persist metrics
- `grafana-data`: Persist dashboards

---

## Mod√®le ML D√©tails

### Training Configuration

**Dataset**:
- Source: `data/estadistical.csv`
- Samples: 1000
- Features: 21 (input) + 1 (target)
- Target: Binary classification
  - 0 = Bad Credit (Reject)
  - 1 = Good Credit (Approve)

**Train/Test Split**:
- Training: 700 samples (70%)
- Testing: 300 samples (30%)
- Stratified split (preserve class distribution)

**Evaluation Metrics**:
- Accuracy
- Precision, Recall, F1-Score (per class)
- Confusion Matrix

### Model Signature

MLflow infers model signature from training data:

```python
signature = infer_signature(X_train, pipeline.predict(X_train))
```

**Input**: CreditApplicationInput (21 features)
**Output**: int (0 or 1)

---

## API REST Endpoints

### 1. GET `/`

**Description**: Home page
**Response**: HTML file (index.html)
**Status**: 200 OK

### 2. GET `/api/health`

**Description**: Health check endpoint
**Response**:
```json
{
  "status": "healthy",
  "model_path": "/app/model/model.pkl",
  "model_loaded": true,
  "timestamp": "2024-12-14T10:30:45.123456"
}
```
**Status**: 200 OK (or 503 Service Unavailable)

### 3. GET `/api/model-info`

**Description**: Model metadata
**Response**:
```json
{
  "name": "RDF_score_pipeline",
  "version": "1",
  "stage": "Production",
  "description": "RandomForest Credit Score Model"
}
```
**Status**: 200 OK

### 4. POST `/api/predict`

**Description**: Single prediction
**Request Body**:
```json
{
  "Duration in month": 12,
  "Credit amount": 5000.0,
  "Installment rate in percentage of disposable income": 2,
  "Age in years": 35,
  "Number of existing credits at this bank": 1,
  "Number of people being liable to provide maintenance for": 1,
  "Status of existing checking account": "A12",
  "Credit history": "A32",
  "Savings account/bonds": "A61",
  "Present employment since": "A73",
  "Job": "A173",
  "Purpose": "A43",
  "Personal status and sex": "A93",
  "Other debtors / guarantors": "A101",
  "Property": "A121",
  "Other installment plans": "A143",
  "Housing": "A152",
  "Telephone": "A192",
  "foreign worker": "A201"
}
```

**Response**:
```json
{
  "prediction": 1,
  "probability_good_credit": 0.85,
  "probability_bad_credit": 0.15,
  "risk_level": "LOW",
  "model_version": "1",
  "timestamp": "2024-12-14T10:30:45.123456"
}
```
**Status**: 200 OK

### 5. POST `/api/predict-batch`

**Description**: Batch predictions
**Request Body**:
```json
{
  "applications": [
    { /* CreditApplicationInput 1 */ },
    { /* CreditApplicationInput 2 */ },
    ...
  ]
}
```

**Response**:
```json
{
  "predictions": [
    { /* PredictionResponse 1 */ },
    { /* PredictionResponse 2 */ },
    ...
  ],
  "total_processed": 10,
  "model_version": "1",
  "timestamp": "2024-12-14T10:30:45.123456"
}
```
**Status**: 200 OK

### 6. POST `/api/reload-model`

**Description**: Force reload model from registry
**Response**: Success message
**Status**: 200 OK

### 7. GET `/metrics`

**Description**: Prometheus metrics endpoint
**Response**: Text format (OpenMetrics)
```
# HELP credit_predictions_total Total number of predictions
# TYPE credit_predictions_total counter
credit_predictions_total{prediction_type="single",status="success"} 42.0
credit_predictions_total{prediction_type="single",status="error"} 2.0
...
```
**Status**: 200 OK

### 8. GET `/docs`

**Description**: Swagger UI
**Response**: Interactive API documentation
**Status**: 200 OK

### 9. GET `/redoc`

**Description**: ReDoc API documentation
**Response**: Alternative API documentation
**Status**: 200 OK

---

## Monitoring & Observabilit√©

### Prometheus Metrics

#### Counters

1. **credit_predictions_total**
   - Labels: `prediction_type` (single/batch), `status` (success/error)
   - Incremented on each prediction request
   - Cumulative count

2. **credit_predictions_good_total**
   - Incremented when prediction == 1 (Good Credit)
   - Subset of total predictions

3. **credit_predictions_bad_total**
   - Incremented when prediction == 0 (Bad Credit)
   - Subset of total predictions

4. **api_request_errors_total**
   - Labels: `endpoint`, `error_type`
   - Tracks API errors by endpoint

5. **model_load_attempts_total**
   - Labels: `status` (success/failure)
   - Tracks model loading attempts

#### Histograms

1. **credit_prediction_duration_seconds**
   - Buckets: 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0
   - Measures request latency
   - Auto-instrumented by prometheus-fastapi-instrumentator

#### Gauges

1. **active_models_total**
   - Number of models currently loaded in memory
   - Real-time count

### Prometheus Configuration

**Config File**: `prometheus.yml`

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'credit-score-api'
    static_configs:
      - targets: ['credit-score-api:8000']
    metrics_path: '/metrics'
    scrape_interval: 15s

  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
```

**Storage**:
- TSDB Path: `/prometheus`
- Retention: 30 days
- Time-series indexed by labels

### Grafana Dashboards

**Pre-provisioned**: `grafana/provisioning/dashboards/credit-score-dashboard.json`

**Visualizations**:
1. **Prediction Volume** (Time series)
   - Total predictions over time
   - Good vs Bad split

2. **Latency Distribution** (Histogram)
   - P50, P95, P99 latencies
   - Track API performance

3. **Error Rate** (Gauge)
   - Percentage of failed requests
   - Alert threshold: > 5%

4. **Model Load Status** (Gauge)
   - Active models loaded
   - Load success/failure ratio

5. **Credit Distribution** (Pie chart)
   - Percentage Good vs Bad predictions
   - Real-time update

**Alerting Rules**: `alert_rules.yml`
- High error rate
- Long latency
- Model unavailable
- Prometheus down

---

## üìä R√©sum√© Architecture

### Caract√©ristiques Cl√©s

‚úÖ **Production-Ready**:
- Health checks sur tous les services
- Error handling et logging
- Graceful shutdown
- Automated restart policies

‚úÖ **Scalable**:
- Stateless API design
- Model caching pour performance
- Batch prediction support
- Metrics for monitoring

‚úÖ **Maintainable**:
- Clear separation of concerns
- Type hints with Pydantic
- MLflow for model versioning
- Docker for reproducibility

‚úÖ **Observable**:
- Prometheus metrics
- Grafana dashboards
- Health checks
- Detailed logging

‚úÖ **Secure**:
- Input validation
- CORS configurable
- Error messages non-exposing internals
- Dependency pinning

### Points d'Extension

1. **Ajouter des mod√®les** :
   - Train nouveau mod√®le
   - Register dans MLflow
   - Update model loading logic

2. **Am√©liorer preprocessing**:
   - Modifier CustomPreprocessor
   - Retrain avec nouvelles transformations
   - New model version

3. **Ajouter des features**:
   - Extend CreditApplicationInput
   - Update preprocessing
   - Retrain avec nouvelles donn√©es

4. **Alertes additionnelles**:
   - D√©finir dans alert_rules.yml
   - Configure dans Grafana
   - Notification channels

---

## üöÄ D√©ploiement

### Pr√©-requis
- Docker >= 20.10
- Docker Compose >= 1.29
- 2GB RAM minimum
- 5GB disk space

### Commandes

```bash
# Build et d√©marrage
docker-compose up -d

# V√©rifier les logs
docker-compose logs -f api

# Arr√™t
docker-compose down

# Volume cleanup
docker volume prune
```

### Endpoints Accessibles

- **API**: http://localhost:8000
- **Swagger Docs**: http://localhost:8000/docs
- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3000 (admin/admin123)

---

**Document g√©n√©r√©**: 14 D√©cembre 2024
**Version Architecture**: 2.0.0
**Status**: Production Ready
